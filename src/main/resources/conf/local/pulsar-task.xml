<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl" ?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <property>
        <name>pulsar.config.id</name>
        <value>local</value>
    </property>

    <!-- persist -->
    <property>
        <name>storage.crawl.id</name>
        <value>information_tmp</value>
        <description>Crawl pages for opinion mining</description>
    </property>

    <!-- net -->
    <property>
        <name>pulsar.master.host</name>
        <value>localhost</value>
    </property>

    <property>
        <name>pulsar.master.hostname</name>
        <value>localhost</value>
    </property>

    <!-- crawl -->
    <property>
        <name>crawl.max.distance</name>
        <value>2</value>
    </property>

    <!-- fetch -->
    <property>
        <name>fetch.concurrency</name>
        <value>5</value>
    </property>

    <property>
        <name>fetcher.threads.per.queue</name>
        <value>-1</value>
        <description>This number is the maximum number of threads that
            should be allowed to access a queue at one time. Setting it to
            a value > 1 will cause the Crawl-Delay value from robots.txt to
            be ignored and the value of fetch.queue.min.delay to be used
            as a delay between successive requests to the same server instead
            of fetch.queue.delay.
        </description>
    </property>

    <property>
        <name>recent.days.window</name>
        <value>3600</value>
    </property>

    <property>
        <name>pulsar.upstream.url</name>
        <value>http://master:8182/api</value>
    </property>

    <property>
        <name>indexer.url</name>
        <!--<value>http://master:8983/solr/information_tmp</value>-->
        <value>http://master:8983/solr/information_1101_integration_test</value>
    </property>

    <property>
        <name>mapreduce.job.reduces</name>
        <value>2</value>
    </property>

</configuration>